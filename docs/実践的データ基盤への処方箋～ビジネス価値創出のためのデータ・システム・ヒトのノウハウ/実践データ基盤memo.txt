■はじめに
・データ活用の現状
　正しい意思決定が目的

・データ活用のためにはデータ基盤が必要
　真のデータ活用とは、一時的ではなく継続的に企業の成長を支えること。

・データ基盤をつくるための道具や知識が揃ってきた
　・道具が揃ってきた
　　ETL製品、DWH製品、BI製品
　・知識も揃ってきた
　　データレイク、データウェアハウス、データマート

・データ基盤を十分に活用できているとは言い切れない
　・データ基盤をつくれても、ビジネス価値を創出できない。

・データ基盤の活用には、知識や技術だけでなく現場のノウハウが必要
　・現場のノウハウがあれば、アンチパターンに陥らない。
　　企業にとって意味のあるアウトプット
　　ただデータを集めるのは失敗の前兆
　・現場のノウハウがあれば、継続的な改善をするために必要なことがわかる
　　※「レポートの利用状況を監視することが重要」
　　
・データ、システム、ヒトのノウハウ
　第１章：データ。データの整備、フィードバックサイクル
　第２章：システム基礎知識、アンチパターン
　第３章：組織づくりやガバナンス　
　
・データ基盤の全体像と組織
　・データ基盤の全体像
　・データ基盤を支える組織
　　・データエンジニア：データの収集、蓄積
　　・データスチュワード：データの整備、データ活用をサポート
　　・組織長

・想定する読書
・本書では書いていないこと
	

■第１章　データ活用のためのデータ整備
　データの流れのどこに問題が生じるのか
　1章では、データが生成されてから活用されるまでの一連の流れを解説
　1-1節：データ基盤の一連の流れ
　1-2～1-4節：データの生成元の整備
　1-5～1-10節：データの流れに沿ってデータ基盤を構成する各層を解説
　1-11節：サービスレベル＝ITサービスの品質水準
　1-12節：データスチュワード：データ整備
　※1-11,1-12 ができないとアンチパターンに陥りやすい。　


　■１－１　データの一連の流れを把握し、入口から出口まで書き出す
　　データが生成されてから活用されるまでの一連の流れを解説。
　
　　■データソースからユースケースまでの流れ	
　　　・データソース
　　　・データ収集：2章で扱う
　　　・データレイク層：
　　　　・データソースのデータをそのままコピーしたデータ。
　　　　・加工や結合をしない。
　　　　・データソースと1対1
　　　・データウェアハウス層：
　　　　・加工・結合したデータを置く場所。
　　　　・共通指標となるデータを置く。
　　　　・外部webサイトでも同じ商品を販売していたら、それらも組み合わせて「売上」という横断の指標を集計するなど
　　　・データマート層
　　　　・加工・結合したデータを置く場所
　　　　・特定用途向けのデータ
　　　　・「毎週のジャンル別の売上」
　　　　・用途ごとに作るので、ユースケースと1対1
　　　・ユースケース
　　　　・データ基盤の用途。
　　　・メタデータ
　　　　・データを説明するためのデータ
　　　　・スキーマ情報
　　　　・更新・参照情報
　　　　・データの利用状況を確認
　　　※三層構造は、
　　　　・Bill Inmon 氏の「CIF(コーポレートインフォメーション・ファクトリー)」
　　　　・青木峰郎氏「10年戦えるデータ分析入門」
　　　　・ゆずたそ氏ブログ記事「データ基盤の3分類と進化的データモデリング」
　　■入口と出口を洗い出すCRUD表
　　　入口：データソース
　　　出口：ユースケース
　　　CRUD表：
　　　　C（Create）：データを生成する
　　　　R（Read）：データを参照する
　　　　U（Update）：データを更新する
　　　　D（Delete）：データを削除する
　　　※コメント：入口と出口を明確にする。入口は明確。出口は社内データ抽出システムで。

　　■データ基盤に関する用語集をまとめる
　　　・自社のデータの流れを書き出す
　　　・データ基盤に関する用語をドキュメントに書いておく。


　■１－２　データの品質は生成元のデータソースで担保する
　　■データソースとは何か
　　　オリジナルのデータ、あるいはそのデータの発生源

　　■なぜデータソースの品質に注意すべきか
　　　・Garbage In Garbage Out
　　　・例えば、不整合データを見つけた時、一時的にはdwhでクレンジング、恒久的な対応としてはデータソースを修正するよう働きかける。
　　　　※クレンジングは1-7で。
　　　　・不整合例：顧客データを見ると購買回数が3回、購買履歴を見ると2件。。
　　　・データソースに問題があると関連業務に影響している可能性あり。
　　　・上流の問題を下流でカバーしても、労力が余計にかかる上、問題の原因が解決されないので、リスクを抱え続けることになる。
　　　★データの品質はデータソースで担保
　　■データの生成過程を知る
　　　・ECサイトの売上を得るだけでも、「webサイトの売上データベース」をデータソースとするか「銀行の入出金」をデータソースとするか、簡単ではない。
　　　・ユースケースの目的に合うデータソースと集計が必要。
　　　・データソースの品質担保は絶対条件。
	
　■１－３　データが生じる現場を把握して業務改善につなげる
　　■データソースの詳細を把握する方法
　　　・データの全体像を把握するには、前述のCRUD表が役に立つ。
　　　・個々のデータソースの詳細を把握するために、ERDの書き方を解説。
　　　・業務レイヤの書き方、業務レイヤの明確化から業務改善の提案方法まで例示
　　
　　■ERD（実体関連図）を書こう
　　　・ERD（Entity Relationship Diagram : 実体関連図）
　　　・これにより「商品データには最新の価格しか掲載されていない」などの問題に気付ける。
　　　・「どのようなデータを記録するか」というログ要件を企画・開発時に定めたい。
　　■業務レイヤ
　　　・著者の造語。
　　　・データ生成の現場を下記4レイヤに分けたもの：業務レイヤ
　　　　・ロール：作業の実施者
　　　　・オペレーション：ロールがとる行動
　　　　・アプリケーション：ロールが行動する際に使う道具のこと
　　　　・ストレージ：データを実際に保存する場所。
　　　※エンタープライズ・アーキテクチャ（EA）という分野を参考にしたらしい。

　　■業務レイヤで課題の原因と改善策を考える
　　　ここは結構大事な話。DXの進め方について書かれている。

　　■組織の枠を超えてデータ生成の現場を考えよう
　　　・ステークホルダー間の利害の対立が課題にあがる。
　　　　・データに関する問題を検知できるのはデータ活用者
　　　　・問題を解消できるのはデータ生成者
　　　・組織の枠を超えて改善のしくみをつくる必要がある。
　　　解決策1. 組織が「課題に気づく」状態をつくる
　　　解決策2. 「解決したいと思える」状態をつくる。
　　　　インセンティブ設計を見直す
　　　解決策3. 「簡単に解決できる」状態をつくる
　　　　データ生成におけるUXのデザイン
	
　■１－４　データソースの整備ではマスタ・共通ID・履歴の３つを担保する
　　■データ整備で問題を解決しよう
　　　「マスタ」「共通ID」「履歴」が生成されていない現場が多い。

　　■マスタデータを生成しよう
　　　部署横断のマスタデータと業務手順書を機能させる

　　■共通IDを生成しよう
　　　全社共通の商品IDを導入する。
　　　これもインセンティブ設計大事。

　　■履歴データを生成しよう
　　　商品説明などの過去データを上書きや消すのはアンチパターン。
　　　過去データが必要になったときにやり直せない。
　　　履歴を残す方法
　　　　・非正規化して、最新情報だけの商品テーブルと編集履歴テーブルをもつ
　　　　・イミュータブルデータモデル。Yoshitake Kawashima 氏が提唱。
　　　　　上書き（Upsate）を減らすための指針
　　　マスタデータは更新・削除ではなく、次のバージョンのデータを追加するのが良い。

	
　■１－５　データレイク層の一箇所にデータのソースのコピーを集約する
　　■データレイク層とは何か
　　　データレイクのデータは、データソースと1対1の関係にある。
　　　重要：
　　　・何も加工していない、ただのコピーであることが重要。
　　　・仮にデータの中身に誤りがあったとしても、修正や加工をせず、そのまま集約する。
　　
　　■どのようにデータレイクをつくるか
　　　※詳しくは2章。
　　　システム構築
　　　・オブジェクトストレージにファイル形式でデータを置く
　　　・データウェアハウス製品という分析用DBに取り込む
　　　データソースからデータレイクへデータ転送方法
　　　・ETLツールの活用
　　■現場で生じるデータレイク層の課題
　　　「データレイクがデータレイクになっていない」ことで問題が起きる。
　　　よくある問題
　　　・分析用に集計してデータレイクに連携するケース
　　　・複数箇所にデータレイクをつくってしますケース
　　■なぜデータを一箇所に集めるべきか
　　　・データレイクは部署横断で複数のデータを集約する場所。
　　　・部署・システムを横断してデータを活用することで、顧客体験やビジネス価値を向上できる。

	
　■１－６　データウェアハウス層では分析用DBを使って共通指標を管理する
　　■データウェアハウス層とは何か
　　　・共通指標となるデータ、ならびにそのデータの置き場。
　　　・複数のデータを統合・蓄積して、意思決定に活用できるように整理したデータが置かれる。
　　　・例１。複数のデータソースに散在した顧客情報を「ユーザID」で紐づけた「分析用の顧客テーブル」
　　　・例２。自社ECサイト、外部webサイト、オフラインイベントで同じ商品を販売」している場合、「売上」という横断の指標（共通指標）を集計する。
　　　・データウェアハウス製品で集計・管理するのが望ましい。
　　
　　■なぜ共通指標を集計すべきか
　　　・部署横断のデータ活用を進めるため
　　　・重要：横断的な指標についてはSSOT(Single Source of Trust:信頼できる唯一の情報源)として、一箇所で定めておく。

　　■なぜ分析用ＤＢで共通指標を集計・管理すべきか
　　　分析用DBは他のツールから参照されることを前提につくられている。
　　　BI などはそのBI独自の環境に閉じていたりする。外部連携が難しい

	
　　■１－７　共通指標は本当に必要とされるものを用意する
　　　■どのようにデータウェアハウス層をつくるか
　　　　dwh層では、データクレンジングのあとに、加工や集計を行ってスタースキーマと共通指標を作成して管理します。
　　　　・データクレンジング：欠損埋め、重複削除、名寄せ
　　　　・スタースキーマの作成：購買履歴（ファクト）+購買日時（ディメンション）
　　　　・共通指標の集計：例えば月次売上
　　　■手順1. データクレンジングの実施
　　　　欠損や重複を修正。名寄せ。
　　　　※これらはデータソース側で修正されるべき。
　　　　※クレンジングはdwhで実施する。レイクで実施しない。
　　　
　　　■手順2. スタースキーマの作成
　　　　スタースキーマやスノーフレークスキーマ：ディメンショナルモデリング
　　　　ディメンションテーブルは分析の切り口
　　　
　　　■手順3. 共通指標の集計
　　　　購入履歴を年月、商品、場所などの切り口（ディメンション）で、売上や購入数を集計する。
　　　■初期段階ではデータウェアハウス層はつくらない。
　　　　自社にとっての共通指標が定まらないうちはdwhをつくらない。
　　　　「データソース→データレイク」
　　　　「ユースケース→データマート」


　■１－８　特定用途に利用するデータマートはユースケースを想定してつくる
　　■データマート層とは何か
　　　・特定の利用者、特定の用途向けに加工・整理したデータ、ならびにその置き場。
　　　・すぐに使える完成品。
　　　・データマート層は用途（ユースケース）と1対1。
　　　・最初はデータマートから作る。
　　　・データマートかdwhか迷う場合は時期尚早なのでマートに置く。
　　
　　■なぜユースケースごとにデータを管理すべきか
　　　メリットは以下の3点
　　　・影響範囲を制限できる。
　　　・集計ロジックを再利用できる。過去の似たユースケースのロジックを参考に新たなロジックをつくる。
　　　・システムの応答時間が速くなる。

　　■どのようにデータマートをつくるか
　　　・データソースとデータレイクが一対一の関係にある。
　　　・データレイクとデータウェアハウスとデータマートの依存関係が１つのワークフローエンジンで管理されている
　　　・データマートとユースケースが一対一の関係にある
　　
　　■現場で生じるデータマート層の課題とその解決法
　　　1. データマートが多すぎる
　　　2. データが分断される

　　※共通指標：dwh, 個別指標：dm

	
　■１－９　ユースケースを優先的に検討しツールの整備を逆算する
　　■ユースケースとは何か
　　　※本書ではデータ基盤の用途をユースケースと呼ぶ
　　　ユースケースの例は省略
　　
　　■なぜユースケースに注目すべきか
　　　・データ基盤をつくるのはユースケースを実現するため。
　　　・開発・運用コストをユースケースの便益が上回っているという状態を目指す。
　　　・実務では最初にユースケースを検討することが望ましい。

　　■どのようにユースケースを定めるか
　　　・最初に、自社あるいは担当事業について、目標、現状、課題、施策を洗い出す。
　　　※中長期経営計画で設定されているはず。　
　　　例　省略
　　　■詳細に検討する

　　　■データ活用施策の概要を設計する
　　　　「どの顧客または社員の」「どの作業まはは判断を」「どのように置き換えるか」
　　　※これらの設計では業務改善やUXデザインの手法が役に立つ。
　　　例：
　　　　顧客への価値提供であればカスタマージャーニーマップ
　　　　社員への価値提供であればバリューストリームマッピングや業務フロー
　　　参考書籍
　　　　・カスタマージャーニーマップ（ 加藤 希 尊 著「 はじめて の カスタマージャーニーマップワークショップ」 翔 泳 社, 2018）
　　　　・バリューストリームマッピング（ メアリー・ポッペンディーク, トム・ポッペンディーク 著, 高 嶋 優 子, 天野 勝, 平鍋 健児 翻訳「 リーン 開発 の 本質」 日経 BP, 2008） 
　　　　・業務 フロー 図（「 ユーザー 要件 を 正しく 実装 へ つなぐ システム 設計 の セオリー」 リックテレコム, 2016）
　
　　　　　■データ利用状況を5W1Hで特定できると、設計の際に便利です。

　　　　　■導入後は以下の3点に注目してモニタリングする。
　　　　　　・導入したツールが活用されているか
　　　　　　・期待する効果が得られているか
　　　　　　・想定外のトラブルや労力が発生していないか

　　　　　■アンチパターン
　　　　　　・事業目標にそぐわない課題を解く
　　　　　　・優先順位が低い施策を進める
　　　　　　・データ利用の5W1Hを想定せずに現場に押し付ける
　　　　　　・一度のリリースに全力をかける
　　　　　データ基盤の担当者はビジネスとデータをつなげることを常に意識しましょう。
　　　　　思考の9割をユースケースに向ける
　　■現場で生じるユースケースの課題
　　　ユースケースを考慮せずに、システム開発者の都合だけでデータの流れを設計すると、利用者がデータを使わなくなる。
　　　※データ基盤チームがツールを指定するような場面。
　　　　部署や役割によって最適なツールが異なる。
　　　　　Excel, Tabeau, Redash, Jpyter Notebook
	
　■１－１０　データの調査コストを減らすためにメタデータを活用する
　　■メタデータとは何か
　　　メタデータは「このデータはどのようなデータなのか」を知るために付与される情報
　　　・データの作成者
　　　・データの作成日時
　　　・データに個人情報が含まれているか
　　　・データが文字列なのか数値なのか
　　　・その数値の単位はcmなのか日本円なのか
　　　・データが誰にどのくらい参照されているのか
　　　・データを保管する義務のある期間

　　■なぜメタデータを管理すべきか
　　　データの調査コストを削減するため。

　　■どのようにメタデータを管理するか
　　　・管理ツールは、分析用DBやメタデータ管理ツール
　　　　分析用DBの多くは、監査機能として
　　　　　「そのデータが誰によっていつ生成されたのか」
　　　　　「そのデータは誰によっていつ参照されているのか」
　　　・データソースとデータレイク層
　　　　　各データの説明文を作成することから始める。
　　　・データウェアハウス層とデータマート層
　　　　　ワークフローエンジンやETLツールでメタデータを扱う

　　■現場で生じるメタデータの課題と対処法
　　　・メタデータの管理を始める場合、まずはデータ生成者がデータベースに説明文を書くだけで十分。
　　　・データ生成者の存在を無視して「メタデータのための専用ツールや専門部隊」を導入すると年単位では失敗するケースが多い。
　　　・データ生成者を巻き込むことが必須。
	
　■１－１１　サービスレベルを設定・計測して改善サイクルにつなげる
　　■サービスレベルとは何か
　　　・サービスの品質水準。
　　　　サービスの品質は大まかに「便利」と「安心」の2種
　　　　　簡単にアクセスできる便利さと整備済みのデータを使える安心感
　　　・サービスレベルの改善サイクル
　　　　・目標設定
　　　　・関係者との合意
　　　　・現状の計測
　　　　・課題の特定
　　　　・必要な施策の実施
　　　　・結果の振り返り
　　　・ITIL（Information Technology Infrastructure Library）IT管理のノウハウ集
　　　・SRE
　　　　これらでもサービスレベルに言及されている。

　　■なぜサービスレベルを計測するか
　　　・サービスの品質を改善するには、システムではなくサービスに注目する。計測する。
　　　　・この２つの要素が揃って初めてサービス品質の改善が実現する。
　　　■システムではなくサービスに注目する
　　　　・システム単体ではなく、サービス全体としての品質の改善を目指す。
　　　■計測することの重要性
　　　　計測ができていないと何をどれくらい改善すればよいのか判断できない。
　　　
　　■どのようにサービスレベルを設定・計測するか
　　　・まずはサービスレベルの目標を設定する。
　　　　・データ利用者のユースケースをヒアリングする
　　　　・そのユースケースにおいて暗黙的に期待されているサービスレベルを可視化する
　　　・サービスレベルはユースケースごとに設定する。

　　　
　　■現場で生じるサービスレベルの課題と対処法
　　　・サービスレベルに過剰な品質目標を設定していないか注意する。
　　　　足りていないのは人材ではなく、品質のコントロールというケースも。
　　　・個人を特定できる情報（PII : Personally Identifible Information）は扱いたくない
　　　・財務データは自由にアクセスできるように設定することが多い。　


　■１－１２　データ基盤の品質を支えるデータスチュワードの役割を設ける
　　■データスチュワードとは何か
　　　本書ではデータ整備の推進者。データ活用者にとっての相談窓口
　　　データについて最も相談を受けている人がいたら、その人物が事実上のデータスチュワード。

　　■なぜデータスチュワードが必要か
　　　データ基盤のサービス品質を担保するために不可欠な存在。
　　　・データ利用者からの問い合わせから「このデータにアクセスしたい」「このデータが使いにくい」といった課題を検知する。
　　　・データソース側へのフィードバックやデータ利用者へデータソースの背景を説明など
　　　・「データを収集する役割」や「データを活用する役割」ではなく「その間をつなぐ役割」
　　　・サービスレベルを定義、計測、改善し、サポート提供や利用促進を行う。

　　■データスチュワードはどう振る舞うか
　　　主に２つの役割
　　　・問い合わせの対応
　　　・データ整備の推進
　　　　・ボトムアップの課題検知とトップダウンの目標実現

　　■現場で生じるデータスチュワードの課題と対処法
　　　問い合わせ対応などの受動的な活動と、品質改善などの能動的な活動の両立。
　　　　問い合わせ対応に追われ、品質改善に工数を費やせないという課題が生じる。
　　　　まずは現状を可視化する。
　　　　　1. 問い合わせ対応と改善活動を案件として捉え、リスト（バックログ）にする。
　　　　　2. 優先順位をつけ、優先順位が高いものから着手する。
　　　　　3. バックログを使って以下を計測する。
　　　　　　1週間で追加される新規案件数
　　　　　　解消できる案件数
　　　　　　各案件を解消するまでの時間
　　　　　4. 50%ルールを設ける。問い合わせ対応など運用作業を50%以下に抑える。
　　　　　5. 週に1回はバックログを見ながら、その週の活動の振り返りを行う。
　　　　　　・「問い合わせ内容の傾向」
　　　　　　・「改善施策の優先度」
　　　　　　・「改善活動の時間を確保するための施策」

■第２章　データ基盤システムの作り方
　データエンジニアの役割がデータを収集する部分に重点を置く

　■２－１　一般的なデータ基盤の全体像と分散処理の必要性を理解する
　　■データ基盤のつくり方は一般化されてきた

　　■データ基盤を構成するシステムコンポーネント

　　■大量のデータには分散処理が必要

	
　■２－２　データソースごとに収集方法が違うこと、その難しさを理解する
　　■データ収集は難しい
　　　データソースごとに収集方法を使い分ける必要があるため、データ収集はデータ基盤の中でも取り扱いの難しいコンポーネント
　　　・ストレージからファイルorデータベースからテーブル
　　　・負荷は与えてはいけないデータベース
　　　・データの量
　　　・個人情報

　　■データソースの種類ごとの収集方法
　　　・ファイルの収集
　　　・API呼び出し、スクレイピング
　　　・データベース
　　　・ログファイル
　　　・端末データ
　　■コラム：データを収集せずに分析に利用する「フェデレーション」
　　　・データソースにあるデータを直接分析に利用する。
　　　・データソースとデータウェアハウスのデータを掛け合わせることができる
　　　・データソースに意図せず負荷を与えてしまうこともある
　　　・Redshiftの横串検索やBigQueryのCloudSQL連携クエリ


　■２－３　ファイルを収集する場合は最適なデータフォーマットを選択する
　　■ファイルデータの収集方法
　　　一般的な方法
　　　・データソース側で生成したファイルをファイルシステムに配置し、配置の完了をイベントとしてキューに投入する。
　　　・データ基盤は配置完了の通知を受領したら、ファイルシステムにデータを取りに行く。
　　　・取得したデータをデータレイクに蓄積する。
　　　※ポイントは、ファイルシステムとは別に配置の完了を通知するしくみをつくること
　　　※キューを使わない場合、配置完了を示すファイル「トリガファイル」をファイルシステムに配置する方法も一般的
　　　

　　■ファイルの中身を厳格に管理したい場合はデータ構造も一緒に収集する

　　■データの量を減らしたい場合はParquetを検討する
	Parquet については2-15で詳解


　■２－４　APIのデータ収集では有効期限や回数制限に気を付ける
　　■APIによるデータ収集とは
　　　・データ分析の文脈でAPIという言葉を使う場合、APIエンドポイントとデータフォーマットのこと意味することが多い
　　　・APIエンドポイント
　　　　・https://example.com/xxx_data といったURLのような文字列で表わし、データを取り出す場所とその方法を示す。
　　　・データフォーマットは、このAPIエンドポイントから取得できるデータの形式。多くはJSON。
　　
　　■APIからデータを収集する方法
　　　

　　■API実行回数制限やAPIキーの有効期限に注意
　　　・多くのAPIで制限がある。「リクエストは1秒に1回まで」「1日に1万回まで」など
　　　・よくある失敗は、PoCの段階では取得するデータが少なく問題が起きないが、本番運用がはじまり取得するデータが多くなると実行回数制限に引っ掛かり障害になる。
　　　・APIキーの有効期限。有効期限切れに注意。APIキーの交換などの運用イベントを忘れずに

	
　■２－５　SQLを利用したデータベース収集ではデータベースへの負荷を意識する
　　■企業にとって重要なデータはデータベースに入っている
　　　データベースからデータを収集する主な方法３つ
　　　・SQL利用
　　　・ファイル経由
　　　・更新ログ収集

　　■SQLを利用したデータベース収集

　　■テーブルが大きい場合はフェッチを活用する
　　　・対象のテーブルのサイズが数GByteで小さい場合は、SELECT文を発行してデータを取得し、それを格納する。
　　　・データサイズが100GByteを超えるような場合、収集処理が動くコンピュータのメモリに乗らないので、カーソルを用いる。

　　■収集が間に合わない場合はテーブルの一部だけを収集する
　　　この方法は、収集対象のテーブルが追記だけされるテーブルの場合と追記と更新もされる場合で異なる。
　　　・追記だけの場合
　　　　　例えば、作成日付という列の値をもとに対象データを取り込む。where句
　　　・
　　■それでも間に合わない場合はSQLを並列実行する

　　■SQLによる収集はデータベースへの負荷が大きいためレプリカを用意する
　　　データベースへの負荷の主な３つ
　　　・キャッシュ汚染
　　　・長時間クエリ
　　　・一時ファイルによるディスク圧迫


　■２－６　データベースの負荷を考慮したデータ収集では、エクスポートやダンプファイル活用を視野に入れる
　　■データをファイルにエクスポートして収集する
　　　・レプリカの準備は費用や手間がかかり、簡単ではない。
　　　・レプリカ複製の代替手段として、データをファイルにエクスポートしてファイル経由でデータを収集する
　　　ファイルエクスポート連携の２つの注意点
　　　・ファイルシステムの準備
　　　・ワークフローエンジン（エクスポートと収取）の構築運用コスト
　　　ファイルにエクスポートのデメリット２つ
　　　・ファイルのサイズはテーブルのサイズより大きくなる
　　　・データベースに対する負荷はゼロではない

　　■ダンプファイルを利用する
　　　

　
　■２－７　更新ログ経由のデータベース収集はデータベースの負荷を最小限にしてリアルタイムに収集できる
　　■データではなく操作を収集する
　　　「操作を収集する」とは、データそのものではなくデータに対する操作が記録された「更新ログ」を収集する。

　　■操作が記録された更新ログを収集する
　　　・更新ログを出力するよう設定。OracleならREDOログ、MySQLならバイナリログが更新ログ。
　　　・更新ログを復元用データベースに取り込む。復元用データベースがデータソースのデータベースと同じ内容になったらデータレイクに取り込む。
　　　・更新があったデータだけ取り込むので収集するデータ量が減る。
　　　■収集するデータ量が減るメリット３つ
　　　　・データ収集速度が向上
　　　　・データベースからデータ基盤に至るネットワークの帯域が小さくてもよい。
　　　　・データベースに対する負荷が最小になる
　　　■更新ログ収集のデメリット３つ
　　　　・専用の製品を使う必要がある。有償で高価であることが多い。
　　　　・収集の仕組みが複雑になる
　　　　・収集対象となるテーブルの列の選択や行の絞り込みができない
　　■コラム：レプリカから収集する方法と更新ログ収集は何が違う？
　　　もともと更新ログはレプリカをつくる仕組みなので似ている
　　　違う点：複製したデータベースの管理者が異なる。更新ログから複製したデータベース」はデータ基盤側の管理

　　■更新ログ収集はCDCツールが本命
　　　・CDCツール　Change Data Capture
　　　　・CDCツールを使うと復元用データベースを準備しなくてよい
　　　　・データの変更を検知して取得する
　　　　・起動しておけば、ほぼリアルタイムにデータベースのデータを収集できる。
　　　　・高価、、
　　　注意点２つ
　　　　データレイクが頻繁な更新に耐えられるか
　　　　障害で処理が止まったときの再実行が難しい
　　　　　感想：運用難易度が高い。。。

　
　■２－８　各データベース収集の特徴と置かれた状況を理解して使い分ける
　　■データベース収集方法のまとめ
　　　本に表がある

　　■使い分けのコツ
　　　著者の経験によると
　　　・まず最初に考えるべき方法は「レプリカからSQL」
　　　・レプリカがない場合、
　　　　　負データソースのデータベースが重要な業務との連携が少なくデータ収集の負荷に耐えられる場合は「SQL」
　　　　・負荷を考慮しなければならない場合は「エクスポート」「データベースダンプ」「CDCツール」
　　　　　　「エクスポート」が一番安く実現できる
　　　・「更新ログからDB復元」はメリットがない

　　■どの方式もうまくいかない場合
　　　　データベースにデータを入れているアプリケーションからデータを収集する作戦


　■２－９　ログ収集はエージェントのキャパシティに注意
　　■ログとは　
　　　・データ分析の文脈においてのログ収集とは、分析対象の振る舞いを記録する時系列のデータ
　　　・よくある分析の対象となるログの１つは、Webサーバのアクセスログ
　　　　・アクセスした時間
　　　　・アクセスした元のIPアドレス
　　　　・アクセスに用いた端末情報（ユーザエージェント情報）
　　　　・アクセスしたURL
　　　　・Webアプリケーションが設定した、ユーザを識別する情報
　　　他はアプリケーションのログなど

　　■ログはログ収集エージェントで収集する
　　　　ログ収集エージェントがバッファを持っている点

　　■ログ収集できる製品
　　　オープンソースは、Tresure Data社のfluentdやfluent-bit、Elastic社のLogstash
　　　クラウドサービスなら、AWSのCloudWatch、GCPのCloud Logging Agent

	
　■２－１０　端末データの収集は難易度が高いためできるだけ製品を利用し無理なら自作する
　　■端末データは大量だが有用
　　　・端末データ：ブラウザイベント、スマホアプリイベント、IoTデバイスデータ

　　■ブラウザイベントやスマホアプリイベントはデータ収集製品を利用する
　　　・まず最初に検討すべきは欲しいデータを収集できる製品がないかを探す
　　　・ブラウザイベントであれば、アクセス解析ツール
　　　　　Adobe Analytics やGoogle Analytics
　　　・スマホアプリイベントであれな、
　　　　　Google Analytics for Firebase

　　■自作する場合は分散メッセージキューを使う
　　　・IoTデバイスデータの収集は自作でデータ収集のしくみをつくることが多い。
　　　・イベントデータはログデータと比べて10倍100倍以上の大きさになることもある。
　　　・流量も安定しない。
　　　・そのため、大量のイベントをいったん受け止めておくしくみとして、分散メッセージキューが必要。

　　■分散メッセージキューの注意すべき特徴
　　　　分散システムであるがゆえに、以下の３つに気を付ける
　　　　・順序性保証の有無
　　　　・メッセージの重複の有無
　　　　・可視性タイムアウト
　　　　理想は順序性保証あり、メッセージの重複なし、可視性タイムアウトが長い

　　■分散メッセージキューをうまく運用するコツ
　　　２つのコツ
　　　・デッドレターをうまく扱う
　　　・バックプレッシャー

　　■具体的なシステムのつくり方

　
　■２－１１　ETL製品を選ぶポイントは利用するコネクタの機能性とデバッグのしやすさ
　　■ETL製品とは
　　　ETL製品の分類方法２つと選定のポイント
　　　ETL製品の分類方法２つ
　　　　提供形態の違い
　　　　複雑な加工ができるかどうか

　　■使うコネクタの機能を重視する

　　■ソースコードレベルでデバッグしやすいものを利用する
　　　　コネクタのコードはオープンにされているものもある。

　　■エンジニアがいなければプログラミングレスのETL製品も選択肢の１つ

　
　■２－１２　データレイクでは収集したデータをなくさないようにする
　　■収集したデータを原則そのまま蓄積する

　　■データレイクには冗長化でき容量が拡張できる製品を選ぶ

　　■ファイルはオブジェクトストレージに蓄積する

　　■CSVやJSONデータはデータベースに入れてもOK

　　■データがオンプレミスにあってもデータレイクはクラウドにする


　■２－１３　データウェアハウスには抽出や集計に特化した分析用DBを採用する
	

　■２－１４　分析用DBはクラウド上で使い勝手が良い製品を選ぶ
	

　■２－１５　列指向圧縮を理解して分析用DBが苦手な処理をさせないように気を付ける
	

　■２－１６　処理の量や開発人数が増えてきたらワークフローエンジンの導入を検討する
	

　■２－１７　ワークフローエンジンは「専用」か「相乗り」かをまず考える


■第３章　データ基盤を支える組織
	■３－１　アセスメントによって組織の現状を客観的に把握する

	■３－２　組織の状況に合わせて組織構造を採用する　

	■３－３　データ組織の成功に必要な要因を理解する

	■３－４　データ組織を構成する職種と採用戦略の基本を押さえる

	■３－５　データ活用とセキュリティはトレードオフの関係にあることを理解する

	■３－６　組織の利益となるデータのセキュリティポリシーとそのセキュリティ基準を決める

	■３－７　適切な権限設定とリスク管理方法を定める

	■３－８　データ利用や権限管理などの運用ルールをドキュメント化する

	■３－９　担当、見直しサイクル、判断基準を決めてデータやツールの棚卸を定期的に行う

	■３－１０　不正アクセスに備えてデータ保護や匿名加工技術を適用する

	■３－１１　監査では評価方法を理解して客観性を担保する

